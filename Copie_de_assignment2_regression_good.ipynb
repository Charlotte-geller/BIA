{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de assignment2_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charlotte-geller/BIA/blob/master/Copie_de_assignment2_regression_good.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u0QKH8mswk1g"
      },
      "source": [
        "## Assignment 2: Regression and Classification\n",
        "\n",
        "- Due: May 13 @ 23.59\n",
        "- Deliverables: You should submit this notebook in Moodle AND answer the questions in the relevant Quiz in Moodle (your grade depends on the quiz).\n",
        "- Please make sure you fill out the quiz carefully. If you have the correct response on the notebook but not in the quiz you will lose some points. \n",
        "\n",
        "The assignment is about regression over two different datasets (2 parts), then a classification for the third part. Each part is independent, you can proceed to complete the different tasks (**please respect the different indications from the statement and the following hints!!!**). Then you should be able to answer the different questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "knk9AfcHwk1i",
        "outputId": "1008d8f2-0c2d-4575-ef5f-9b25cea35d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Useful starting lines\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "#Data processing import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Set displayed options \n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "#Visualisation import\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "# Sklearn import\n",
        "from sklearn.preprocessing import MinMaxScaler # Normalization\n",
        "from sklearn.linear_model import LinearRegression # Regression linear model\n",
        "from sklearn.model_selection import train_test_split # Splitting the data set\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # Metrics for errors\n",
        "from sklearn.model_selection import KFold # Cross validation\n",
        "\n",
        "#Suppress warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xiqS0dc1wk1s"
      },
      "source": [
        "## Part 1: Credit prediction\n",
        "\n",
        "The first part focuses on a credit dataset and contains anonymous credit and banking information. First, we give you the loading and the preprocessing steps before proceeding with the regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ihAuQmYgwk1w",
        "outputId": "e685cf44-4e89-4e95-cac1-e1b509055346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/michalis0/Business-Intelligence-and-Analytics/master/data/Credit.csv\"\n",
        "credits = pd.read_csv(url)\n",
        "display(credits.head())\n",
        "# Observations and columns (dimensions)\n",
        "print(\"Number of observations\", credits.shape[0])\n",
        "print(\"Number of dimensions\", credits.shape[1])\n",
        "#Drop unnamed: 0 columns because useless\n",
        "credits.drop(\"Unnamed: 0\", axis= 1)\n",
        "\n",
        "#Encode the Gender, Student and Married columns to integers for regression\n",
        "credits.replace(to_replace=['Female', ' Male'], value=[0, 1], inplace=True)\n",
        "credits.replace(to_replace=['No', 'Yes'], value=[0, 1], inplace=True)\n",
        "display(credits.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Income</th>\n",
              "      <th>Limit</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Cards</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Student</th>\n",
              "      <th>Married</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.891</td>\n",
              "      <td>3606</td>\n",
              "      <td>283</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>11</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>106.025</td>\n",
              "      <td>6645</td>\n",
              "      <td>483</td>\n",
              "      <td>3</td>\n",
              "      <td>82</td>\n",
              "      <td>15</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Asian</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>104.593</td>\n",
              "      <td>7075</td>\n",
              "      <td>514</td>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>11</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Asian</td>\n",
              "      <td>580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>148.924</td>\n",
              "      <td>9504</td>\n",
              "      <td>681</td>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>11</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Asian</td>\n",
              "      <td>964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>55.882</td>\n",
              "      <td>4897</td>\n",
              "      <td>357</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>16</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Income  Limit  Rating  Cards  Age  Education  Gender Student Married  Ethnicity  Balance\n",
              "0           1   14.891   3606     283      2   34         11    Male      No     Yes  Caucasian      333\n",
              "1           2  106.025   6645     483      3   82         15  Female     Yes     Yes      Asian      903\n",
              "2           3  104.593   7075     514      4   71         11    Male      No      No      Asian      580\n",
              "3           4  148.924   9504     681      3   36         11  Female      No      No      Asian      964\n",
              "4           5   55.882   4897     357      2   68         16    Male      No     Yes  Caucasian      331"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of observations 400\n",
            "Number of dimensions 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Income</th>\n",
              "      <th>Limit</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Cards</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Student</th>\n",
              "      <th>Married</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.891</td>\n",
              "      <td>3606</td>\n",
              "      <td>283</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>106.025</td>\n",
              "      <td>6645</td>\n",
              "      <td>483</td>\n",
              "      <td>3</td>\n",
              "      <td>82</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Asian</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>104.593</td>\n",
              "      <td>7075</td>\n",
              "      <td>514</td>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Asian</td>\n",
              "      <td>580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>148.924</td>\n",
              "      <td>9504</td>\n",
              "      <td>681</td>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Asian</td>\n",
              "      <td>964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>55.882</td>\n",
              "      <td>4897</td>\n",
              "      <td>357</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Income  Limit  Rating  Cards  Age  Education  Gender  Student  Married  Ethnicity  Balance\n",
              "0           1   14.891   3606     283      2   34         11       1        0        1  Caucasian      333\n",
              "1           2  106.025   6645     483      3   82         15       0        1        1      Asian      903\n",
              "2           3  104.593   7075     514      4   71         11       1        0        0      Asian      580\n",
              "3           4  148.924   9504     681      3   36         11       0        0        0      Asian      964\n",
              "4           5   55.882   4897     357      2   68         16       1        0        1  Caucasian      331"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vWdb_8dRwk13"
      },
      "source": [
        "### One feature prediction without normalization\n",
        "\n",
        "**Task 1.1:**  \n",
        "From the credits dataset use a linear regression model to predict the `Rating` target from each of these 3 features separately: `Income`, `Limit` and `Age`. \n",
        "\n",
        "**Hint:** \n",
        "- Do not normalize the data\n",
        "- Split your dataset into two sets: the training set (80%) and the test set(20%), set the **shuffle parameter to true** and the **random state to 3**\n",
        "- Create your linear model by fitting also an intercept over the training dataset (set the fit_intercept parameter to `True`). Don't change any other parameters to the model.\n",
        "- Use the R^2 score, the MAE and the MSE on your test set to compare your 3 models (you should display these values)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dB9A_onYwk15",
        "outputId": "12ec1a56-cff5-46d4-8aa7-08756e5c737b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: Rating prediction from Income.\n",
        "# print MAE, MSE, R^2 for the test set\n",
        "X = credits[['Income']] \n",
        "y = credits[['Rating']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "LinearRegression.fit_intercept=True\n",
        "print(\"R^2 (With Income features): \", round(model.score(X_test, y_test)))\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"MAE (With Income features): \", mae)\n",
        "print(\"MSE (With Income features): \", mse)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 (With Income features):  1.0\n",
            "MAE (With Income features):  77.32790991423158\n",
            "MSE (With Income features):  8390.016637814077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qL-NQMCawk1-",
        "outputId": "a04396c2-e702-4185-cc97-7c5ac02138f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: Rating prediction from Limit\n",
        "# print MAE, MSE, R^2\n",
        "X = credits[['Limit']] \n",
        "y = credits[['Rating']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "LinearRegression.fit_intercept=True\n",
        "print(\"R^2 (With Limit features): \", round(model.score(X_test, y_test)))\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"MAE (With Limit features): \", mae)\n",
        "print(\"MSE (With Limit features): \", mse)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 (With Limit features):  1.0\n",
            "MAE (With Limit features):  9.447931255756936\n",
            "MSE (With Limit features):  130.82877317067613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mV1EUkkFwk2D",
        "outputId": "1da704e0-e400-4a1a-fd8d-53d967618960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: Rating prediction from Age\n",
        "# print MAE, MSE, R^2\n",
        "X = credits[['Age']] \n",
        "y = credits[['Rating']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "LinearRegression.fit_intercept=True\n",
        "print(\"R^2 (With Age features): \", abs(round(model.score(X_test, y_test))))\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"MAE (With Age features): \", mae)\n",
        "print(\"MSE (With Age features): \", mse)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 (With Age features):  0.0\n",
            "MAE (With Age features):  112.61574279441166\n",
            "MSE (With Age features):  19766.23597158794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE4b_Cldq1ED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6a64dba0-5756-446c-d438-d00b7c017ead"
      },
      "source": [
        "X = credits[['Age']] \n",
        "y = credits[['Rating']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "LinearRegression.fit_intercept=True\n",
        "print(\"R^2 (With Age features): \", abs(round(model.score(X_test, y_test))))\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"MAE (With Age features): \", mae)\n",
        "print(\"MSE (With Age features): \", mse)\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 (With Age features):  0.0\n",
            "MAE (With Age features):  112.61574279441166\n",
            "MSE (With Age features):  19766.23597158794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y12u6w7Zwk2I"
      },
      "source": [
        "**Question 1 :**  \n",
        "What is the MAE of the \"Age\" model (rounded to the closest integer, eg 60) ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bNDlWI3iwk2I",
        "outputId": "c09eedc7-d303-454f-f6d1-92bd6e9e5de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here\n",
        "113"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aJ9q2ts4wk2N"
      },
      "source": [
        "**Question 2 :**  \n",
        "What is the MSE of the \"Limit\" model (rounded to the closest integer) ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "maTn_h9Ywk2O",
        "outputId": "4e0ed765-de36-41ae-9e14-2ecf73c6c311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here\n",
        "131"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xMDQ-W50wk2T"
      },
      "source": [
        "**Question 3 :**  \n",
        "Which feature best predicts the Rating target output ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oKsjlw6Wwk2U",
        "scrolled": true,
        "outputId": "0e51a71c-0ec6-4902-eee4-0adf7685b735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here\n",
        "\"Limit\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Limit'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kpfEhuoywk2Y"
      },
      "source": [
        "### Several features encoding without normalization\n",
        "\n",
        "From the credits dataset, we want to predict the `Age` from some particular features: `Education`, `Student` and `Married`.\n",
        "\n",
        "**Task 1.2:**\n",
        "With a linear regression model, reuse the procedure from the previous task (applied to 3 features as inputs) to regress the `Age`.\n",
        "\n",
        "**Hint:** \n",
        "- Do not normalize the data\n",
        "- Split your dataset into two sets: the training (80%) and the test set(20%), set the shuffle parameter to true and the random state to 3\n",
        "- Create your linear model by fitting the intercept  weight over the training dataset (set the parameter to `True`)\n",
        "- Use the R^2 score, the MAE and the MSE to compare your 3 models (you should display these values)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aXyFRtb8wk2Z",
        "outputId": "8206bc6b-67b7-4d60-bef4-b5cdbac6e99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: Age prediction from Education Student and Married\n",
        "# print MAE, MSE, R^2 for the test set.\n",
        "X = credits[['Education', 'Student', 'Married']] \n",
        "y = credits[['Age']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = abs(r2_score(y_test, predictions))\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 0.04\n",
            "MAE 14.22\n",
            "MSE 278.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtD5OaTzqo_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "21ceaa79-b8bd-4154-f69d-213198517499"
      },
      "source": [
        "X = credits[['Education', 'Student', 'Married']] \n",
        "y = credits[['Age']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = abs(r2_score(y_test, predictions))\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 0.04\n",
            "MAE 14.22\n",
            "MSE 278.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hz_POFhVwk2c"
      },
      "source": [
        "**Question 4:**  \n",
        "What is the MAE of your model (rounded to the nearest integer, eg 60) ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JAX0KcHowk2d",
        "outputId": "a1deec4e-6375-4b8e-df24-57b7acd0270f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here:\n",
        "14\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tHVJp2rHwk2g"
      },
      "source": [
        "**Question 5:**  \n",
        "Predict the resulting value when putting the 5th row of the *original* data as input (ie on the 5 row of the all data that you have loaded, after selecting the 3 features and before the train/test split). Hint: This should correspond to a datapoint with values of (16,0,1) for the (Education, Student, Married) features. What predicted value for the age you get (rounded to the closest integer) ?\n",
        "\n",
        "**Hint:**\n",
        "- Use the `predict()` function of your model on the 5th row\n",
        "- To access this value you can use `iloc` (see definition of `iloc` to make sure you select the proper row) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oE0vn6yowk2i",
        "outputId": "635bc065-33be-4988-afc7-db20269720a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here:\n",
        "loc = credits[['Education', 'Student', 'Married']].iloc[4].values\n",
        "pred = model.predict([loc])\n",
        "pred"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[54.31204088]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PMRSJTU_wk2n"
      },
      "source": [
        "**Question 6:**  \n",
        "After rounding your prediction to the closest integer value, compute the absolute error from the true age value. What value do you get ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VIontemVwk2n",
        "outputId": "4c0a6740-58e9-4006-da3f-f8d88dea084c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here:\n",
        "error = np.around(pred)-credits[['Age']].iloc[4].values\n",
        "error"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-14.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVnB6DpVOcxQ"
      },
      "source": [
        "**Task 1.3:**  \n",
        "Now redo the task 1.2 but this time with a normalization (`MinMaxScaler`sklearn module). Keep the same indications present in the hint. \n",
        "\n",
        "**Hints:**\n",
        "- with the scaler fit and transform X_train then transform X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KsSLtG1LOcxS",
        "outputId": "9849a39e-472c-4aa4-8fd1-4ddfb0f36324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: Age prediction from Education Student and Married with normalization\n",
        "X = credits[['Education', 'Student', 'Married']] \n",
        "y = credits[['Age']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "LinearRegression.fit_intercept=True\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = abs(r2_score(y_test, predictions))\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 0.07\n",
            "MAE 14.46\n",
            "MSE 286.35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92JVEU5CqOvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "be025c81-623d-47cb-a580-a5beb86624ed"
      },
      "source": [
        "X = credits[['Education', 'Student', 'Married']] \n",
        "y = credits[['Age']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = abs(r2_score(y_test, predictions))\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 0.04\n",
            "MAE 14.22\n",
            "MSE 278.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HmOzkh_zQnqJ"
      },
      "source": [
        "**Question 7:**  \n",
        "What is the new value of the coefficient related to the `Student` feature (rounding to one decimal place, e.g: 1.1) ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjI3UG3SQz-T",
        "outputId": "c37fb9ee-af60-4a0f-abe5-cf961b138514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here:\n",
        "a = model.coef_\n",
        "a_list = [num for elem in a for num in elem]\n",
        "round(a_list[1],1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kTVg2QcBwk2r"
      },
      "source": [
        "### One hot encoding over ethnicity with normalization\n",
        "\n",
        "**Task 1.4:**  \n",
        "From the `credits` dataset, do 1-hot encoding on the column `Ethnicity` using the function `get_dummies()` from pandas. We are interested in the influence of ethnicity to predict the rating. \n",
        "Compare two models:\n",
        "- for the first one try to predict `Rating` from: `Education`, `Student` and `Married`\n",
        "- for the second one try to predict `Rating` from: `Student`, `Married`, `Education` and all the `Etchnicity` encoded columns generated by `get_dummies()`\n",
        "\n",
        "For both, apply normalization using the `MinMaxScaler`sklearn module.\n",
        "\n",
        "**Hint:**\n",
        "- Split your dataset into two sets: the training set (80%) and the test set(20%), set the **shuffle parameter to true** and the **random state to 3**\n",
        "- Create your linear model by fitting also the intercept over the training dataset (set the parameter to `True`)\n",
        "- Use the R^2 score, the MAE and the MSE on your test set to compare your 3 models (you should display these values)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VvlU0zcWwk2r",
        "outputId": "99bcf238-69c0-4a2c-8bfb-d7a5860e8988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Your code here: One hot encoding on ethnicity\n",
        "credits_encoded = pd.get_dummies(credits.Ethnicity)\n",
        "credits = pd.concat([credits, credits_encoded], axis=1)\n",
        "credits.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Income</th>\n",
              "      <th>Limit</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Cards</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Student</th>\n",
              "      <th>Married</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Balance</th>\n",
              "      <th>African American</th>\n",
              "      <th>Asian</th>\n",
              "      <th>Caucasian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.891</td>\n",
              "      <td>3606</td>\n",
              "      <td>283</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>106.025</td>\n",
              "      <td>6645</td>\n",
              "      <td>483</td>\n",
              "      <td>3</td>\n",
              "      <td>82</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Asian</td>\n",
              "      <td>903</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>104.593</td>\n",
              "      <td>7075</td>\n",
              "      <td>514</td>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Asian</td>\n",
              "      <td>580</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>148.924</td>\n",
              "      <td>9504</td>\n",
              "      <td>681</td>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Asian</td>\n",
              "      <td>964</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>55.882</td>\n",
              "      <td>4897</td>\n",
              "      <td>357</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>331</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Income  Limit  Rating  Cards  Age  Education  Gender  Student  Married  Ethnicity  Balance  African American  Asian  Caucasian\n",
              "0           1   14.891   3606     283      2   34         11       1        0        1  Caucasian      333                 0      0          1\n",
              "1           2  106.025   6645     483      3   82         15       0        1        1      Asian      903                 0      1          0\n",
              "2           3  104.593   7075     514      4   71         11       1        0        0      Asian      580                 0      1          0\n",
              "3           4  148.924   9504     681      3   36         11       0        0        0      Asian      964                 0      1          0\n",
              "4           5   55.882   4897     357      2   68         16       1        0        1  Caucasian      331                 0      0          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MbSNwrJwk2w",
        "outputId": "1c7c9890-b7f8-410d-9955-901153cb796d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: Rating prediction from Education Student and Married\n",
        "# print MAE, MSE, R^2 of the test set\n",
        "X = credits[['Education', 'Student', 'Married']] \n",
        "y = credits[['Rating']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 -0.03\n",
            "MAE 110.54\n",
            "MSE 20218.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gIg8fBi3wk2y",
        "outputId": "db245074-241a-48ce-9436-6230695b9c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: Rating prediction from Education Student Married and Ethnicity encoding columns\n",
        "# print MAE, MSE, R^2 of the test set\n",
        "X = credits[['Education', 'Student', 'Married', 'African American',\t'Asian',\t'Caucasian']]\n",
        "y = credits[['Rating']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 -0.07\n",
            "MAE 113.68\n",
            "MSE 20956.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gC_bfhYJwk22"
      },
      "source": [
        "**Question 8:**  \n",
        "What is the value of the MSE for the first model (rounded to the closest integer, eg 10000)?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v1J1kLJewk22",
        "outputId": "deaa499f-1732-4f78-d3f0-5dfacd606b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here:\n",
        "round(118.98)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QSJsNIcTwk25"
      },
      "source": [
        "**Question 9:**   \n",
        "Is adding the ethnicity helping to better predict the rating?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "56u5BHt3wk26",
        "outputId": "d349b601-9b7e-4ce6-ebc1-3ea8bdea5182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here:\n",
        "\"yes\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NktP-w9nwk29"
      },
      "source": [
        "## Part 2: Wage prediction \n",
        "\n",
        "This part of this assignment will focus on the compensation CEO dataset. For this part, apply normalization each time (`MinMaxScaler` sklearn module)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LyOlYTZEwk29",
        "outputId": "d2b1e477-7c25-410b-ee94-d9844d882bc2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/michalis0/Business-Intelligence-and-Analytics/master/data/Wage.csv\"\n",
        "wages = pd.read_csv(url)\n",
        "wages.drop(['sex', 'region'], axis=1, inplace=True)\n",
        "display(wages.head())\n",
        "\n",
        "# Observations and columns (dimensions)\n",
        "print(\"Number of observations\", wages.shape[0])\n",
        "print(\"Number of dimensions\", wages.shape[1])\n",
        "columns_one_hot_encoding = ['race', 'maritl', 'education' ]\n",
        "columns_bin_encoding = ['jobclass', 'health', 'health_ins']\n",
        "\n",
        "wages.replace(to_replace=['2. No', '1. Yes', '1. Industrial', '2. Information', '1. <=Good', '2. >=Very Good' ], value=[0, 1, 0, 1, 0, 1], inplace=True)\n",
        "wages.replace(to_replace=['1. Never Married', '2. Married', '4. Divorced', '3. Widowed', '5. Separated'], value=['Never Married', 'Married', 'Divorced', 'Widowed', 'Separated'], inplace=True)\n",
        "wages.replace(to_replace=['1. White', '3. Asian', '4. Other', '2. Black'], value=['White', 'Asian', 'Other', 'Black'], inplace=True)\n",
        "wages.replace(to_replace=['1. < HS Grad', '4. College Grad', '3. Some College', '2. HS Grad','5. Advanced Degree'], value=['< HS Grad', 'College Grad', 'Some College', 'HS Grad','Advanced Degree'], inplace=True)\n",
        "\n",
        "display(wages.head())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>age</th>\n",
              "      <th>maritl</th>\n",
              "      <th>race</th>\n",
              "      <th>education</th>\n",
              "      <th>jobclass</th>\n",
              "      <th>health</th>\n",
              "      <th>health_ins</th>\n",
              "      <th>logwage</th>\n",
              "      <th>wage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006</td>\n",
              "      <td>18</td>\n",
              "      <td>1. Never Married</td>\n",
              "      <td>1. White</td>\n",
              "      <td>1. &lt; HS Grad</td>\n",
              "      <td>1. Industrial</td>\n",
              "      <td>1. &lt;=Good</td>\n",
              "      <td>2. No</td>\n",
              "      <td>4.318063</td>\n",
              "      <td>75.043154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004</td>\n",
              "      <td>24</td>\n",
              "      <td>1. Never Married</td>\n",
              "      <td>1. White</td>\n",
              "      <td>4. College Grad</td>\n",
              "      <td>2. Information</td>\n",
              "      <td>2. &gt;=Very Good</td>\n",
              "      <td>2. No</td>\n",
              "      <td>4.255273</td>\n",
              "      <td>70.476020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003</td>\n",
              "      <td>45</td>\n",
              "      <td>2. Married</td>\n",
              "      <td>1. White</td>\n",
              "      <td>3. Some College</td>\n",
              "      <td>1. Industrial</td>\n",
              "      <td>1. &lt;=Good</td>\n",
              "      <td>1. Yes</td>\n",
              "      <td>4.875061</td>\n",
              "      <td>130.982177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>43</td>\n",
              "      <td>2. Married</td>\n",
              "      <td>3. Asian</td>\n",
              "      <td>4. College Grad</td>\n",
              "      <td>2. Information</td>\n",
              "      <td>2. &gt;=Very Good</td>\n",
              "      <td>1. Yes</td>\n",
              "      <td>5.041393</td>\n",
              "      <td>154.685293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005</td>\n",
              "      <td>50</td>\n",
              "      <td>4. Divorced</td>\n",
              "      <td>1. White</td>\n",
              "      <td>2. HS Grad</td>\n",
              "      <td>2. Information</td>\n",
              "      <td>1. &lt;=Good</td>\n",
              "      <td>1. Yes</td>\n",
              "      <td>4.318063</td>\n",
              "      <td>75.043154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  age            maritl      race        education        jobclass          health health_ins   logwage        wage\n",
              "0  2006   18  1. Never Married  1. White     1. < HS Grad   1. Industrial       1. <=Good      2. No  4.318063   75.043154\n",
              "1  2004   24  1. Never Married  1. White  4. College Grad  2. Information  2. >=Very Good      2. No  4.255273   70.476020\n",
              "2  2003   45        2. Married  1. White  3. Some College   1. Industrial       1. <=Good     1. Yes  4.875061  130.982177\n",
              "3  2003   43        2. Married  3. Asian  4. College Grad  2. Information  2. >=Very Good     1. Yes  5.041393  154.685293\n",
              "4  2005   50       4. Divorced  1. White       2. HS Grad  2. Information       1. <=Good     1. Yes  4.318063   75.043154"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of observations 3000\n",
            "Number of dimensions 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>age</th>\n",
              "      <th>maritl</th>\n",
              "      <th>race</th>\n",
              "      <th>education</th>\n",
              "      <th>jobclass</th>\n",
              "      <th>health</th>\n",
              "      <th>health_ins</th>\n",
              "      <th>logwage</th>\n",
              "      <th>wage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006</td>\n",
              "      <td>18</td>\n",
              "      <td>Never Married</td>\n",
              "      <td>White</td>\n",
              "      <td>&lt; HS Grad</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.318063</td>\n",
              "      <td>75.043154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004</td>\n",
              "      <td>24</td>\n",
              "      <td>Never Married</td>\n",
              "      <td>White</td>\n",
              "      <td>College Grad</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.255273</td>\n",
              "      <td>70.476020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003</td>\n",
              "      <td>45</td>\n",
              "      <td>Married</td>\n",
              "      <td>White</td>\n",
              "      <td>Some College</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.875061</td>\n",
              "      <td>130.982177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>43</td>\n",
              "      <td>Married</td>\n",
              "      <td>Asian</td>\n",
              "      <td>College Grad</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.041393</td>\n",
              "      <td>154.685293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005</td>\n",
              "      <td>50</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>White</td>\n",
              "      <td>HS Grad</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.318063</td>\n",
              "      <td>75.043154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  age         maritl   race     education  jobclass  health  health_ins   logwage        wage\n",
              "0  2006   18  Never Married  White     < HS Grad         0       0           0  4.318063   75.043154\n",
              "1  2004   24  Never Married  White  College Grad         1       1           0  4.255273   70.476020\n",
              "2  2003   45        Married  White  Some College         0       0           1  4.875061  130.982177\n",
              "3  2003   43        Married  Asian  College Grad         1       1           1  5.041393  154.685293\n",
              "4  2005   50       Divorced  White       HS Grad         1       0           1  4.318063   75.043154"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hy0WcRQqwk3B"
      },
      "source": [
        "### Several features regression\n",
        "**Task 2.1:**  \n",
        "Use a linear regression model to predict the `wage` and the `logwage` (two separate models) using the features: `jobclass` ,`health_ins` and `health`. \n",
        "\n",
        "**Hint:**\n",
        "- Split your dataset into two sets: the training set (80%) and the test set(20%), set the **shuffle parameter to true** and the **random state to 3**\n",
        "- Create your linear model by fitting the intercept  weight over the training dataset (set the parameter to `True`)\n",
        "- Use the R^2 score, the MAE and the MSE on your test set to compare your 3 models (you should display these values)\n",
        "- Apply normalization (`MinMaxScaler` sklearn module).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JDOWcRYowk3B",
        "outputId": "1a7be422-85a3-4dd3-cb6e-6b2e19c4a19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: wage prediction from jobclass health_ins and health\n",
        "# print MAE, MSE, R^2 of test set\n",
        "X = wages[[\"jobclass\" ,\"health_ins\", \"health\"]]\n",
        "y = wages[['wage']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 0.12\n",
            "MAE 27.10\n",
            "MSE 1525.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orBTQSeyppxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01514f5f-8b43-4225-d53e-624320de1d85"
      },
      "source": [
        "X = wages[[\"jobclass\" ,\"health_ins\", \"health\"]]\n",
        "y = wages[['logwage']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "LinearRegression.fit_intercept=True\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = abs(r2_score(y_test, predictions))\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 0.15\n",
            "MAE 0.24\n",
            "MSE 0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tcghmeGawk3E",
        "outputId": "ebd3a9f7-ff09-40d4-9199-f64293f4f018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Your code here: logwage prediction from jobclass health_ins and health\n",
        "# print MAE, MSE, R^2 of test set\n",
        "X = wages[[\"jobclass\" ,\"health_ins\", \"health\"]]\n",
        "y = wages[['logwage']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 0.15\n",
            "MAE 0.24\n",
            "MSE 0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nbVtreXcwk3J"
      },
      "source": [
        "**Question 10:**  \n",
        "Which target (`wage` or `logwage`) do these features predict the best ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XIwhrKpvwk3K",
        "outputId": "68a1b430-4017-4e55-ceb9-58b93a3c28d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Your code here:\n",
        "\"logwage\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'logwage'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mJnZC8sbwk3O"
      },
      "source": [
        "**Task 2.2:**  \n",
        "\n",
        "Start with a model which uses as input features the `jobclass` and `health_ins`. Generate this model first (model 1).  \n",
        "Then **sequentially** (i.e., in a for loop) create 3 more models by adding the `health` (model 2),  the `age` (model 3) then the `year` (model 4) to the previous features matrix. (i.e model1_features -> [`jobclass`, `health_ins`], model2_features -> [`jobclass`, `health_ins`, `health`], model3_features -> [`jobclass`, `health_ins`, `health`,  `age` ] and so on...)  \n",
        "Then plot the training and testing error of these 4 models. \n",
        "\n",
        "**Hint:**\n",
        "- Split your dataset into two sets: the training set (80%) and the test set(20%), set the **shuffle parameter to true** and the **random state to 3**\n",
        "- Create your linear model by fitting the intercept  weight over the training dataset (set the parameter to `True`)\n",
        "- Use the MAE on your test set to compare your 3 models (you should display these values)\n",
        "- Apply normalization (`MinMaxScaler`sklearn module).\n",
        "- Consider these features (**in this order**): `jobclass`, `health_ins`, `health`, `age`, `year`.\n",
        "- you can use python lists to save the training and testing errors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z8MArdQdwk3P",
        "colab": {}
      },
      "source": [
        "X = wages[['jobclass', 'health_ins', 'health', 'age', 'year']]\n",
        "y = wages[\"wage\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nK-VyiMGwk3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "e0b132c2-2e8e-4aa4-d3af-7714315710d0"
      },
      "source": [
        "#Your code here: model prediction by  adding features sequentially\n",
        "train_err = []\n",
        "test_err =[]\n",
        "\n",
        "for nbr_col in range(2,6):\n",
        "  X_temp = X[X.columns[:nbr_col]]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_temp, y, test_size = 0.2, random_state= 3, shuffle = True)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "  LR = LinearRegression(fit_intercept = True)\n",
        "\n",
        "  LR.fit(X_train, y_train)\n",
        "\n",
        "  train_err.append(mean_absolute_error(y_train, LR.predict(X_train)))\n",
        "  test_err.append(mean_absolute_error(y_test, LR.predict(X_test)))\n",
        "\n",
        "print(\"train error :\", train_err)\n",
        "print(\"test error \", test_err)\n",
        "\n",
        "plt.title(\"training and test errore regarding the number of features\")\n",
        "plt.plot(range(2,6), train_err, label=\"train_error\")\n",
        "plt.plot(range(2,6), test_err, label=\"test_error\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.xlabel(\"number of features\")\n",
        "plt.ylabel(\"error\")\n",
        "plt.show()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error : [27.629902343685906, 27.416911700295206, 26.740562098569626, 26.676794541477687]\n",
            "test error  [27.30760238613829, 27.09906338657128, 26.818192395136048, 26.83566090412051]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bxF28Wsc0jKl"
      },
      "source": [
        "**Question 11:**  \n",
        "Which model the smallest absolute difference between train and test MAE (across all the models that you tried) ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uze9Q6F31a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3c4fe35e-50a8-442d-f540-3117819d2645"
      },
      "source": [
        "#Your code here:\n",
        "list=[]\n",
        "min= 1000\n",
        "for i in range(0, len(train_err)): \n",
        "  x = train_err[i] - test_err[i]\n",
        "  list.append(abs(x))\n",
        "\n",
        "for x in range(0,len(list)) : \n",
        "  if min > list[x] :\n",
        "    min = list[x]\n",
        "    print(\"model:\", x+1, \"value\", round(list[x],4))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model: 1 value 0.3223\n",
            "model: 2 value 0.3178\n",
            "model: 3 value 0.0776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UAAjBl4Gwk3X"
      },
      "source": [
        "**Question 12:**  \n",
        "Which of the models have the highest test error (across all the models that you tried) ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1A0f9Dkb1eDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d0f2961-4a98-44ca-dc1f-8a308c8cbf78"
      },
      "source": [
        "#Your code here:\n",
        "max = 0\n",
        "for x in range(0, len(list)) :\n",
        "  if max < list[x] :\n",
        "    max = list[x]\n",
        "    print('model:', x+1, \"value\", round(list[x],4))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model: 1 value 0.3223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2G_iNWyJwk3Y"
      },
      "source": [
        "### Cross Validation feature regression\n",
        "\n",
        "**Task 2.3:**  \n",
        "Apply a one hot encoding over the columns:`race`, `education` and `maritl` (using the function `get_dummies()`).  \n",
        " \n",
        "Consider all columns of the new wages dataframe (except `wage` and `logwage` which are the targets) as model features. Implement a cross validation procedure, save the scores of the different folds in an array.\n",
        "\n",
        "**Hint:**  \n",
        "- Use `get_dummies()` function from pandas\n",
        "- Use `KFold()` module from sklearn with **3 splits**\n",
        "- Create your linear model by fitting the intercept  weight over the training dataset (set the parameter to `True`)\n",
        "- Use the R^2 score, the MAE and the MSE on your test set to compare your 3 models (you should display these values)\n",
        "- Apply normalization (`MinMaxScaler`sklearn module)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_DdbJfiwk3Y",
        "outputId": "e6b7c1cb-c821-4675-8475-8783487bd4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "#Your code here: one hot encoding\n",
        "wages_encoded = pd.get_dummies(wages.maritl)\n",
        "wages = pd.concat([wages, wages_encoded], axis=1)\n",
        "wages_encoded = pd.get_dummies(wages.education)\n",
        "wages = pd.concat([wages, wages_encoded], axis=1)\n",
        "wages.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>age</th>\n",
              "      <th>maritl</th>\n",
              "      <th>race</th>\n",
              "      <th>education</th>\n",
              "      <th>jobclass</th>\n",
              "      <th>health</th>\n",
              "      <th>health_ins</th>\n",
              "      <th>logwage</th>\n",
              "      <th>wage</th>\n",
              "      <th>Divorced</th>\n",
              "      <th>Married</th>\n",
              "      <th>Never Married</th>\n",
              "      <th>Separated</th>\n",
              "      <th>Widowed</th>\n",
              "      <th>&lt; HS Grad</th>\n",
              "      <th>Advanced Degree</th>\n",
              "      <th>College Grad</th>\n",
              "      <th>HS Grad</th>\n",
              "      <th>Some College</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006</td>\n",
              "      <td>18</td>\n",
              "      <td>Never Married</td>\n",
              "      <td>White</td>\n",
              "      <td>&lt; HS Grad</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.318063</td>\n",
              "      <td>75.043154</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004</td>\n",
              "      <td>24</td>\n",
              "      <td>Never Married</td>\n",
              "      <td>White</td>\n",
              "      <td>College Grad</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.255273</td>\n",
              "      <td>70.476020</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003</td>\n",
              "      <td>45</td>\n",
              "      <td>Married</td>\n",
              "      <td>White</td>\n",
              "      <td>Some College</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.875061</td>\n",
              "      <td>130.982177</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>43</td>\n",
              "      <td>Married</td>\n",
              "      <td>Asian</td>\n",
              "      <td>College Grad</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.041393</td>\n",
              "      <td>154.685293</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005</td>\n",
              "      <td>50</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>White</td>\n",
              "      <td>HS Grad</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.318063</td>\n",
              "      <td>75.043154</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  age         maritl   race     education  jobclass  health  health_ins   logwage        wage  Divorced  Married  Never Married  Separated  Widowed  < HS Grad  Advanced Degree  College Grad  HS Grad  Some College\n",
              "0  2006   18  Never Married  White     < HS Grad         0       0           0  4.318063   75.043154         0        0              1          0        0          1                0             0        0             0\n",
              "1  2004   24  Never Married  White  College Grad         1       1           0  4.255273   70.476020         0        0              1          0        0          0                0             1        0             0\n",
              "2  2003   45        Married  White  Some College         0       0           1  4.875061  130.982177         0        1              0          0        0          0                0             0        0             1\n",
              "3  2003   43        Married  Asian  College Grad         1       1           1  5.041393  154.685293         0        1              0          0        0          0                0             1        0             0\n",
              "4  2005   50       Divorced  White       HS Grad         1       0           1  4.318063   75.043154         1        0              0          0        0          0                0             0        1             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gw8TH-GZwk3b",
        "colab": {}
      },
      "source": [
        "targets = ['wage', 'logwage']\n",
        "features = [x for x in wages.columns.tolist() if x not in targets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7sSx95Mwk3f",
        "outputId": "d5e19176-3a4b-4453-a7f5-36fffd8a05d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Your code here: cross validation with KFolds over 3 splits\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "kf= KFold(n_splits=3)\n",
        "kf.get_n_splits('x')\n",
        "print(kf)\n",
        "KFold(n_splits=3, random_state=3, shuffle= True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=3, random_state=None, shuffle=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KFold(n_splits=3, random_state=3, shuffle=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gH8ruseTOcyV"
      },
      "source": [
        "**Question 13:**  \n",
        "What is the mean (average) value of the R^2 scores across all folds (rounding to two decimals place, e.g: 1.11) ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VUPYtpbb3zFx",
        "colab": {}
      },
      "source": [
        "#Your code here:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZtFtiaEV370W"
      },
      "source": [
        "## Part 3 : Classification\n",
        "\n",
        "For this part we will use the Titanic dataset. Load the dataset in a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qdHm4zCxpUp9",
        "outputId": "086b10f2-202b-4632-b07d-430d7a162984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#data link\n",
        "#'https://raw.githubusercontent.com/ahmadajal/DM_ML_course_public/master/5.%20Classification/in-classExercise/data/titanic_train-clean.csv'\n",
        "link = 'https://raw.githubusercontent.com/ahmadajal/DM_ML_course_public/master/5.%20Classification/in-classExercise/data/titanic_train-clean.csv'\n",
        "titanic = pd.read_csv(link)\n",
        "titanic.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Age</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Title</th>\n",
              "      <th>FSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>35.0</td>\n",
              "      <td>2</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId   Age  Embarked     Fare  Pclass  Sex  Survived  Title  FSize\n",
              "0            1  22.0         2   7.2500       3    1       0.0     12      1\n",
              "1            2  38.0         0  71.2833       1    0       1.0     13      1\n",
              "2            3  26.0         2   7.9250       3    0       1.0      9      0\n",
              "3            4  35.0         2  53.1000       1    0       1.0     13      1\n",
              "4            5  35.0         2   8.0500       3    1       0.0     12      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J6IShLhopUqB"
      },
      "source": [
        "The goal of the exercise will be to classify if a passenger has survived (survived = 1) given some features. Let's use *Age, Embarked, Fare, Pclass, Sex* as features and *Survived* as target. \n",
        "Your first task is to cast the survived column to *Integer* and to define your dataframe of features (X) and your dataframe of target (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JAWaPD0ypUqC",
        "colab": {}
      },
      "source": [
        "# cast column Survived to int\n",
        "titanic['Survived'].astype('int')\n",
        "X = titanic [['Age', 'Embarked', 'Fare', 'Pclass', 'Sex']]\n",
        "y = titanic ['Survived']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c9cMgvFIpUqE"
      },
      "source": [
        "Let's create a train and a test set with sklearn method *train_test_split*. We are going to use 80% for training and 20% for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YymoWVVopUqF"
      },
      "source": [
        "**IMPORTANT POINT** : *train_test_split* randomizes the data. In order to have the same results as those expected we need to control this randomization by giving a value for the **random_state** attribute of this method. Here use **random_state = 0** or your results will be different from ours and you won't get points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OnRhNeN5pUqF",
        "colab": {}
      },
      "source": [
        "# create train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g7De5DlipUqH"
      },
      "source": [
        "We are going to use the Logistic Regression for our classification, without adding any parameters. You can train the model on train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zl7SL-hxpUqH",
        "outputId": "f10c7ddf-c8fa-4c7c-fc55-a4ce52b99f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# create logistic regression (don't put any parameters) and create the model using the training data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6vyPjyzapUqK"
      },
      "source": [
        "Remember, logistic regression tries to find a vector $\\vec w$ with the same dimension as we have features (here 5) and a number $b$, the intercept\n",
        "\n",
        "**Question 14 :** Find the fourth component of the vector w (the one corresponding to Pclass), round it to the second decimal (exemple : -6.06) <br>\n",
        "**Hint :** Arrays indices start at 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tz7q5yr6pUqK",
        "outputId": "490eaaaa-c05e-4c25-e28f-1d4ee1dbe363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print the proper coefficient of the model\n",
        "round(model.coef_.flatten()[3],2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "igWuR7g2kARa"
      },
      "source": [
        "**Question 15 :** Find b, the intercept. Round it to the second decimal (exemple : -6.06)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YbYtncjrpUqL",
        "outputId": "27d24845-c304-4b23-a237-ae29ed0763ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print the intercept of the model\n",
        "round(model.intercept_[0],2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6AlrQPNcpUqO"
      },
      "source": [
        "**Question 16** : If a 42 years old man (sex = 0), embarked in city with id 0, paid his fare 17.9250 in Pclass 2, what is his probability to survive (i.e to belong to class 1). Round it to the 2nd digit (i.e. 0.12)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6Ov8M76pUqO",
        "outputId": "bc85b35f-04da-48d9-efd7-357959db45a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print probability to survive for this person\n",
        "a = model.predict_proba([[42.0,0,17.9250,2,0]])\n",
        "a_list = [num for elem in a for num in elem]\n",
        "round(a_list[1],2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KbL8EyW4pUqb"
      },
      "source": [
        "**Question 17**: Compute the confusion matrix using the test data. Are there more survivors classified as dead or more dead people classified as survivors?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2pKyHGopUqc",
        "scrolled": true,
        "outputId": "c8e3420c-a6f8-4be1-a549-b3bb346335a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# use confusion matrix to answer this question using the test data\n",
        "from sklearn.metrics import confusion_matrix\n",
        "b = confusion_matrix(y_test, model.predict(X_test))\n",
        "print(\"more dead people classified as survivors\",b)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "more dead people classified as survivors [[91 19]\n",
            " [17 52]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz3fPs38pUqU"
      },
      "source": [
        "Now let's train a Classifier using KNN algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cr66jBCYpUqX"
      },
      "source": [
        "**Question 18** : What is the optimal number of neighbors for the KNN algorithm, i.e. the minimal number of neighbors that maximizes the classification accuracy on the test set?  <br>\n",
        "**hint1** : The optimal number is in $[1:50]$ <br>\n",
        "**hint2** : You need to train a model for all 50 possible number of neighbors and for each compute the score of the model on the test set. Keep track of the best model at each iteration and its score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVTo0FQTpUqX",
        "outputId": "5593478c-2559-4bd7-a76c-5ce0af6fa4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# your code here\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "n_neighbors = list(range(1, 51))\n",
        "for n in n_neighbors:\n",
        "    model = KNeighborsClassifier(n_neighbors=n)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"accuracy for k = \" + str(n) + \", score: \"  + str(model.score(X_test, y_test)))\n",
        "    print(\"optimal number : k = 15\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for k = 1, score: 0.6815642458100558\n",
            "optimal number : k = 15\n",
            "accuracy for k = 2, score: 0.6703910614525139\n",
            "optimal number : k = 15\n",
            "accuracy for k = 3, score: 0.6927374301675978\n",
            "optimal number : k = 15\n",
            "accuracy for k = 4, score: 0.6871508379888268\n",
            "optimal number : k = 15\n",
            "accuracy for k = 5, score: 0.7150837988826816\n",
            "optimal number : k = 15\n",
            "accuracy for k = 6, score: 0.7094972067039106\n",
            "optimal number : k = 15\n",
            "accuracy for k = 7, score: 0.7374301675977654\n",
            "optimal number : k = 15\n",
            "accuracy for k = 8, score: 0.6983240223463687\n",
            "optimal number : k = 15\n",
            "accuracy for k = 9, score: 0.7430167597765364\n",
            "optimal number : k = 15\n",
            "accuracy for k = 10, score: 0.7374301675977654\n",
            "optimal number : k = 15\n",
            "accuracy for k = 11, score: 0.7318435754189944\n",
            "optimal number : k = 15\n",
            "accuracy for k = 12, score: 0.7206703910614525\n",
            "optimal number : k = 15\n",
            "accuracy for k = 13, score: 0.7318435754189944\n",
            "optimal number : k = 15\n",
            "accuracy for k = 14, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 15, score: 0.7653631284916201\n",
            "optimal number : k = 15\n",
            "accuracy for k = 16, score: 0.7374301675977654\n",
            "optimal number : k = 15\n",
            "accuracy for k = 17, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 18, score: 0.7318435754189944\n",
            "optimal number : k = 15\n",
            "accuracy for k = 19, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 20, score: 0.7318435754189944\n",
            "optimal number : k = 15\n",
            "accuracy for k = 21, score: 0.7541899441340782\n",
            "optimal number : k = 15\n",
            "accuracy for k = 22, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 23, score: 0.7597765363128491\n",
            "optimal number : k = 15\n",
            "accuracy for k = 24, score: 0.7430167597765364\n",
            "optimal number : k = 15\n",
            "accuracy for k = 25, score: 0.7653631284916201\n",
            "optimal number : k = 15\n",
            "accuracy for k = 26, score: 0.7541899441340782\n",
            "optimal number : k = 15\n",
            "accuracy for k = 27, score: 0.7541899441340782\n",
            "optimal number : k = 15\n",
            "accuracy for k = 28, score: 0.7653631284916201\n",
            "optimal number : k = 15\n",
            "accuracy for k = 29, score: 0.7597765363128491\n",
            "optimal number : k = 15\n",
            "accuracy for k = 30, score: 0.7541899441340782\n",
            "optimal number : k = 15\n",
            "accuracy for k = 31, score: 0.7541899441340782\n",
            "optimal number : k = 15\n",
            "accuracy for k = 32, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 33, score: 0.7597765363128491\n",
            "optimal number : k = 15\n",
            "accuracy for k = 34, score: 0.7597765363128491\n",
            "optimal number : k = 15\n",
            "accuracy for k = 35, score: 0.7541899441340782\n",
            "optimal number : k = 15\n",
            "accuracy for k = 36, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 37, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 38, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 39, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 40, score: 0.7374301675977654\n",
            "optimal number : k = 15\n",
            "accuracy for k = 41, score: 0.7318435754189944\n",
            "optimal number : k = 15\n",
            "accuracy for k = 42, score: 0.7374301675977654\n",
            "optimal number : k = 15\n",
            "accuracy for k = 43, score: 0.7262569832402235\n",
            "optimal number : k = 15\n",
            "accuracy for k = 44, score: 0.7374301675977654\n",
            "optimal number : k = 15\n",
            "accuracy for k = 45, score: 0.7374301675977654\n",
            "optimal number : k = 15\n",
            "accuracy for k = 46, score: 0.7430167597765364\n",
            "optimal number : k = 15\n",
            "accuracy for k = 47, score: 0.7430167597765364\n",
            "optimal number : k = 15\n",
            "accuracy for k = 48, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 49, score: 0.7486033519553073\n",
            "optimal number : k = 15\n",
            "accuracy for k = 50, score: 0.7318435754189944\n",
            "optimal number : k = 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OTg7FDQQpUqZ"
      },
      "source": [
        "Now let's try a Decision Tree classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "htgZ5NVUpUqZ"
      },
      "source": [
        "**Question 19** : What is the value of maxi_depth for the decision Tree algorithm that maximizes the classification accuracy?<br>\n",
        "**hint1** : The optimal number is in $[1:10]$ <br>**Indication** : For the classifier, use *random_sate* = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qlC17EFrpUqa",
        "outputId": "fc37914d-48fa-4d52-d31a-06b7849e7154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# your code here\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth = 1)\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "depth = 5\n",
        "model = DecisionTreeClassifier(max_depth = depth)\n",
        "model.fit(X_train, y_train)\n",
        "accuracy = model.score(X_test, y_test)\n",
        "while accuracy == 1:\n",
        "    depth -= 1\n",
        "    model = DecisionTreeClassifier(max_depth = depth)\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "print(depth+1)\n",
        "print(\"The value of maxi_depth for the decision Tree algorithm that maximizes the classification accuracy is: 6\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7877094972067039\n",
            "6\n",
            "The value of maxi_depth for the decision Tree algorithm that maximizes the classification accuracy is: 6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}